{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc6a67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshith_21\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\Roshith_21\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM RMSE: 16.395368619015965\n",
      "Best CatBoost RMSE: 16.520917510889806\n",
      "GradientBoostingRegressor RMSE: 16.51301398872257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshith_21\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshith_21\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshith_21\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('fetal_birth_weight.dat')\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df.drop(columns=['birth_weight'])\n",
    "y = df['birth_weight']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize LightGBM, CatBoost, and GradientBoosting regressors\n",
    "lgbm_model = LGBMRegressor()\n",
    "catboost_model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, verbose=0)\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Hyperparameter tuning for LightGBM\n",
    "lgbm_params = {\n",
    "    'num_leaves': [20, 30, 40],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "lgbm_random = RandomizedSearchCV(estimator=lgbm_model, param_distributions=lgbm_params, n_iter=10, cv=3, random_state=42)\n",
    "lgbm_random.fit(X_train, y_train)\n",
    "best_lgbm_model = lgbm_random.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for CatBoost\n",
    "catboost_params = {\n",
    "    'iterations': [1000, 1500, 2000],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'depth': [4, 6, 8]\n",
    "}\n",
    "catboost_random = RandomizedSearchCV(estimator=catboost_model, param_distributions=catboost_params, n_iter=10, cv=3, random_state=42)\n",
    "catboost_random.fit(X_train, y_train)\n",
    "best_catboost_model = catboost_random.best_estimator_\n",
    "\n",
    "# Train GradientBoostingRegressor for comparison\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the best models to pickle files\n",
    "with open('best_lgbm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_lgbm_model, f)\n",
    "\n",
    "with open('best_catboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_catboost_model, f)\n",
    "\n",
    "# Make predictions with the best models\n",
    "lgbm_pred = best_lgbm_model.predict(X_test)\n",
    "catboost_pred = best_catboost_model.predict(X_test)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "lgbm_rmse = mean_squared_error(y_test, lgbm_pred, squared=False)\n",
    "catboost_rmse = mean_squared_error(y_test, catboost_pred, squared=False)\n",
    "gb_rmse = mean_squared_error(y_test, gb_pred, squared=False)\n",
    "\n",
    "print(f\"Best LightGBM RMSE: {lgbm_rmse}\")\n",
    "print(f\"Best CatBoost RMSE: {catboost_rmse}\")\n",
    "print(f\"GradientBoostingRegressor RMSE: {gb_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbb4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
